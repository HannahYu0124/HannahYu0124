#I usually run the program at Colab. If you're interested, please check the original version here!
#https://colab.research.google.com/drive/1bOfMLvDQSNIdMfSC95IH99XVXgxLLe6q?usp=sharing


#<<Distribution figure>>

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

excel_file=pd.read_excel ('/content/drive/MyDrive/京大/colab/文件檔/HSI/酸/酸度分布.xlsx')
excel_file.to_csv ('/content/drive/MyDrive/京大/colab/文件檔/HSI/酸/酸度分布.csv', index=False)
excel_file
df=excel_file

fig=plt.figure()
ax=fig.add_subplot(111)
#ax.hist(df['HY'], range=(0.2, 0.9), rwidth=1                                                                        )
ax.hist(df['HY'], range=(10, 50), rwidth=1)
ax.set_title('Hei Ye')
#plt.xlabel('Acidity')
plt.xlabel('Brix-acid ratio')
plt.ylabel('number')
plt.show()



#<<Big csv>>

import pandas as pd

# Excel ファイルを読み込む
excel_file_path = '/content/drive/MyDrive/京大/colab/ファイル/HSI/糖/HY/sHY_full.xlsx'
df = pd.read_excel(excel_file_path)

# データを転置する
transposed_df = df.T

# CSV ファイルとして保存する
csv_file_path = '/content/drive/MyDrive/京大/colab/ファイル/HSI/糖/HY/sHY_full.csv'
transposed_df.to_csv(csv_file_path, header=False, index=False)

df


#<<MSC>>

from sys import stdout
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

df = pd.read_csv('/content/drive/MyDrive/京大/colab/文件檔/HSI/糖/YHP/sYHP_full.csv')#, index_col = 0
df
X = df.values[:,1:]
X

# Define MSC correction function
def msc(input_data):

    # Calculate reference spectrum (e.g., average spectrum)
    reference_spectrum = np.mean(input_data, axis=0)

    # Define a new array and populate it with the corrected data
    output_data = np.zeros_like(input_data)
    for i in range(input_data.shape[0]):

        # Fit a linear model between reference spectrum and individual spectra using least squares method
        coeffs = np.linalg.lstsq(reference_spectrum[:, np.newaxis], input_data[i, :][:, np.newaxis], rcond=None)[0]

        # Compute the corrected spectrum using the linear model coefficients
        output_data[i,:] = input_data[i,:] / (reference_spectrum * coeffs[0])

    return output_data

# Apply MSC correction
Xmsc = msc(X)

# Create a new DataFrame with corrected data
new=df.columns[1:]
test=pd.DataFrame(Xmsc, columns=new)

# Add the additional factor column (e.g., 'Acidity') to the new DataFrame

#new_data=pd.Series(df.loc[:,'Acidity'])
#test.insert(0, 'Acidity', new_data)

#new_data=pd.Series(df.loc[:,'Brix/acid ratio'])
#test.insert(0, 'Brix/acid ratio', new_data)

new_data=pd.Series(df.loc[:,'Brix'])
test.insert(0, 'Brix', new_data)

# Save the new DataFrame to CSV
test.to_csv("/content/drive/MyDrive/京大/colab/文件檔/HSI/糖/YHP/sYHP_full_MSC.csv", index=False)


#<<SNV>>

from sys import stdout
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

df = pd.read_csv('/content/drive/MyDrive/京大/colab/文件檔/NIRS/test/糖/表11-38.csv')#, index_col = 0
df
X = df.values[:,1:]
X

#df1 = pd.read_csv('shell-SVG1.csv')#, index_col = 0
#X1 = df1.values[:,2:]
#wl = np.arange(900,1650,3)
#df2 = pd.read_csv('shell-SVG2.csv')#, index_col = 0
#X2 = df2.values[:,11:261]
#wl = np.arange(900,1650,3)

def snv(input_data):

    # Define a new array and populate it with the corrected data
    output_data = np.zeros_like(input_data)
    for i in range(input_data.shape[0]):

        # Apply correction
        output_data[i,:] = (input_data[i,:] - np.mean(input_data[i,:])) / np.std(input_data[i,:])

    return output_data

# Apply correction
Xsnv = snv(X) # Take the first element of the output tuple
Xsnv

# SNV処理をした新しいデータフレームを作成する
new=df.columns[1:]
test=pd.DataFrame(Xsnv, columns=new)
test

#new_data=pd.Series(df.loc[:,'Acidity'])
new_data=pd.Series(df.loc[:,'Brix/acid ratio'])

new_data
#test.insert(0, 'Acidity', new_data)
test.insert(0, 'Brix/acid ratio', new_data)
test

test.to_csv("/content/drive/MyDrive/京大/colab/文件檔/HSI/糖酸比/YHP/rYHP_full_SNV.csv", index=False)

columns=df.columns[1:]
fig = plt.figure(figsize=(12,24))
with plt.style.context(('classic')):   #'ggplot'

    ax1 = plt.subplot(411)
    plt.plot(columns, X.T)
    plt.title('Raw spectra',fontsize = 15)
    plt.ylabel('Absorbance spectra', fontsize = 15)
    plt.xticks(['386.55', '431.18', '492.69', '552.85', '592.64', '643.32', '772.09', '1027.15'] )

    ax2 = plt.subplot(412)
    plt.plot(columns, Xsnv.T)
    plt.xlabel('Wavelength (nm)',fontsize = 15)
    plt.ylabel('Absorbance spectra',fontsize = 15)
    plt.title('SNV',fontsize = 15)
    plt.xticks(['386.55', '431.18', '492.69', '552.85', '592.64', '643.32', '772.09', '1027.15'] )
    plt.show()


#<<SG>>

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import sys
from scipy.signal import savgol_filter

x= pd.read_csv("/content/drive/MyDrive/京大/colab/文件檔/HSI/糖酸比/YHP/rYHP_full.csv")
ax =x.iloc[:,1:]
df = np.array(ax)

data1=[]
for n in range(len(x)):
    n=0+n
    svx = savgol_filter(df[n], 5, 2,deriv=0)
    data1.append(svx)
    n=n+1
index=x.index
columns = x.columns[1:]
test= pd.DataFrame(data1,index=index, columns=columns)

bx = x.iloc[:,0]

cx=bx.rename(index='Acidity')

fx=pd.concat([cx,test], axis=1)
fx.to_csv("/content/drive/MyDrive/京大/colab/文件檔/HSI/糖酸比/YHP/rYHP_full_SG0.csv", index=False)


#<<PLS>>

#酸度
import pandas as pd # pandas のインポート
import numpy as np

dataset= pd.read_csv('/content/drive/MyDrive/京大/colab/文件檔/HSI/酸/HY/HY_full_MSC.csv') # データセットの読み込み #改csv來源

#dataset=df.sample(frac=0.1,random_state=99)
dataset.shape  # データセットのサンプル数、特徴量の数の確認
dataset # 念のため確認

#x1 = dataset.iloc[:, 1:23]
#x2 = dataset.iloc[:, 53:301]
#x = pd.concat([x1, x2], axis=1)

from sklearn.model_selection import train_test_split # ランダムにトレーニングデータとテストデータとに分割。
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True, random_state=99)
autoscaled_x_train = (x_train - x_train.mean()) / x_train.std() # トレーニングデータの説明変数の標準化。平均を引いてから、標準偏差で割ります
autoscaled_x_test = (x_test - x_train.mean()) / x_train.std() # テストデータの説明変数の標準化には、トレーニングデータの平均と標準偏差を用いることに注意してください
autoscaled_y_train = (y_train - y_train.mean()) / y_train.std() # トレーニングデータの目的変数の標準化
from sklearn.model_selection import cross_val_predict # クロスバリデーションにより推定値を計算するために使用
from sklearn.cross_decomposition import PLSRegression # PLS モデル構築やモデルを用いた y の値の推定に使用
from sklearn import metrics # r2 等の指標の計算に使用

max_number_of_components = 20  # 主成分の数
fold_number = 10 # クロスバリデーションのfold数

components = [] # 空の list を作成して、主成分数をこの変数に追加
r2_in_cv_all = [] # 空の list を作成して、主成分数ごとのクロスバリデーション後の r2 をこの list に追加

for component in range(1, max_number_of_components+1):
    model = PLSRegression(n_components=component) # PLS モデルの宣言
    estimated_y_in_cv = pd.DataFrame(cross_val_predict(model, autoscaled_x_train, autoscaled_y_train, cv=fold_number)) # クロスバリデーション推定値の計算し、DataFrame型に変換
    estimated_y_in_cv = estimated_y_in_cv * y_train.std() + y_train.mean() # スケールをもとに戻す
    r2_in_cv = metrics.r2_score(y_train, estimated_y_in_cv) # r2 を計算
    print(component, r2_in_cv) # 主成分数と r2 を表示
    r2_in_cv_all.append(r2_in_cv)  # r2 を追加
    components.append(component) # 主成分数を追加

r2_in_cv_all # 念のため確認
import matplotlib.pyplot as plt # 図の描画に使用
plt.rcParams['font.size'] = 18 # 横軸や縦軸の名前の文字などのフォントのサイズ
plt.scatter(components, r2_in_cv_all) # 散布図
plt.xlabel('number of components') # x 軸の名前
plt.ylabel('cross-validated r2') # y 軸の名前
plt.show() # 以上の設定で描画
max(r2_in_cv_all)
r2_in_cv_all.index(max(r2_in_cv_all)) # クロスバリデーション後の r2 が最大値となる index 番号
optimal_component_number = components[r2_in_cv_all.index(max(r2_in_cv_all))] # 最良の主成分数を optimal_component_number に代入
optimal_component_number # 念のため確認
model = PLSRegression(n_components=optimal_component_number) # model = PLSRegression(20)
model.fit(autoscaled_x_train, autoscaled_y_train) # 回帰モデルの構築

standard_regression_coefficients = pd.DataFrame(np.transpose(model.coef_)) # pandas の DataFrame 型に変換
standard_regression_coefficients.columns = x_train.columns # 変数に対応する名前を、元のデータの変数名に
standard_regression_coefficients.index = ['standard_regression_coefficients'] # 列名を変更
standard_regression_coefficients =standard_regression_coefficients.T
standard_regression_coefficients

#SRCのcsv製作
standard_regression_coefficients.to_csv ('/content/drive/MyDrive/京大/colab/文件檔/HSI/酸/HY/HY_MSC_SRC.csv')
standard_regression_coefficients.sort_values(by='standard_regression_coefficients', ascending=False)

wavelength_S=x.columns[0]
wavelength_E=x.columns[-1]

estimated_y_train = pd.DataFrame(model.predict(autoscaled_x_train)) # 推定して、pandas の DataFrame 型に変換
estimated_y_train = estimated_y_train * y_train.std() + y_train.mean() # スケールをもとに戻します
estimated_y_train.index = x_train.index # サンプル名を、元のデータのサンプル名に
estimated_y_train.columns = ['estimated_y'] # 列名を変更
estimated_y_train # 念のため確認 #estimated_y_train.to_csv('estimated_y_train_pls.csv') # csv ファイルに保存。同じ名前のファイルがあるときは上書きされますので注意してください
import matplotlib.pyplot as plt
import matplotlib.figure as figure # 図の調整に使用
plt.rcParams['font.size'] = 16.5 # 横軸や縦軸の名前の文字などのフォントのサイズ
plt.figure(figsize=figure.figaspect(1)) # 図の形を正方形に
plt.scatter(y_train, estimated_y_train.iloc[:, 0]) # 散布図。estimated_y_train は 200×1 の行列のため、0 列目を選択する必要があります
#y_max = max(y_train.max(), estimated_y_train.iloc[:, 0].max()) # 実測値の最大値と、推定値の最大値の中で、より大きい値を取得
#y_min = min(y_train.min(), estimated_y_train.iloc[:, 0].min()) # 実測値の最小値と、推定値の最小値の中で、より小さい値を取得
plt.scatter(y_train, estimated_y_train.iloc[:, 0], color="cornflowerblue")

plt.plot([0, 1], [0, 1], 'k-')
plt.yticks(np.arange(0, 1.1, 0.3))
plt.ylim(0, 1)
plt.xticks(np.arange(0, 1.1, 0.3))
plt.xlim(0, 1)

plt.xticks([0, 0.3, 0.6, 0.9])
plt.yticks([0, 0.3, 0.6, 0.9])

plt.xlabel("actual acidity")
plt.ylabel("estimated acidity")
plt.title('training set')
plt.show()

from sklearn import metrics
metrics.r2_score(y_train, estimated_y_train) # r2
metrics.mean_squared_error(y_train,estimated_y_train,squared=False) #RMSE
metrics.mean_absolute_error(y_train, estimated_y_train) # MAE
estimated_y_test = pd.DataFrame(model.predict(autoscaled_x_test)) # 推定して、pandas の DataFrame 型に変換
estimated_y_test = estimated_y_test * y_train.std() + y_train.mean() # スケールをもとに戻します
estimated_y_test.index = x_test.index # サンプル名を、元のデータのサンプル名に
estimated_y_test.columns = ['estimated_y'] # 列名を変更
estimated_y_test # 念のため確
#estimated_y_test.to_csv('estimated_y_test_pls.csv') # csv ファイルに保存。同じ名前のファイルがあるときは上書きされますので注意してください
plt.rcParams['font.size'] = 16.5 # 横軸や縦軸の名前の文字などのフォントのサイズ
plt.figure(figsize=figure.figaspect(1)) # 図の形を正方形に
plt.scatter(y_test, estimated_y_test.iloc[:, 0]) # 散布図。estimated_y_train は 200×1 の行列のため、0 列目を選択する必要があります
#y_max = max(y_train.max(), estimated_y_train.iloc[:, 0].max()) # 実測値の最大値と、推定値の最大値の中で、より大きい値を取得
#y_min = min(y_train.min(), estimated_y_train.iloc[:, 0].min()) # 実測値の最小値と、推定値の最小値の中で、より小さい値を取得
plt.scatter(y_test, estimated_y_test.iloc[:, 0], color="cornflowerblue")

plt.plot([0, 1], [0, 1], 'k-')
plt.yticks(np.arange(0, 1.1, 0.3))
plt.ylim(0, 1)
plt.xticks(np.arange(0, 1.1, 0.3))
plt.xlim(0, 1)

plt.xticks([0, 0.3, 0.6, 0.9])
plt.yticks([0, 0.3, 0.6, 0.9])

plt.xlabel("actual acidity")
plt.ylabel("estimated acidity")
plt.title('test set')
plt.show()

metrics.r2_score(y_test, estimated_y_test) # r2
metrics.mean_squared_error(y_test,estimated_y_test,squared=False) #RMSE
metrics.mean_absolute_error(y_test, estimated_y_test) # MAE
plt.rcParams['font.size'] = 16.5 # 横軸や縦軸の名前の文字などのフォントのサイズ
plt.figure(figsize=figure.figaspect(1)) # 図の形を正方形に
plt.scatter(y_train, estimated_y_train.iloc[:, 0],marker = "o")
plt.scatter(y_test, estimated_y_test.iloc[:, 0],marker = "v")

plt.plot([0,1],[0,1], 'k-')
plt.yticks(np.arange(0, 1.1, 0.3))
plt.ylim(0, 1) # y 軸の範囲の設定
plt.xticks(np.arange(0, 1.1, 0.3))
plt.xlim(0, 1) # x 軸の範囲の設定

plt.xlabel("actual acidity") # x 軸の名前
plt.ylabel("estimated acidity") # y 軸の名前
plt.legend(["train","test"],bbox_to_anchor=(1.03, 1), loc='upper left', borderaxespad=0, fontsize=14)



#<<PLS (exclusive wavelentgh)>>


import pandas as pd
from sklearn.model_selection import cross_val_predict
from sklearn.cross_decomposition import PLSRegression
from sklearn import metrics

dataset = pd.read_csv('/content/drive/MyDrive/京大/colab/文件檔/HSI/酸/NMT/NMT_full_MSC.csv')

y = dataset.iloc[:, 0]

r2value_train = []
r2value_test = []
MAE_train = []
MAE_test = []
RMSEC = []
RMSEP = []
RPDC = []
RPDP = []
LV = []

# 定义不同区段的起始列和结束列
regions = [(23, 301), (1, 23, 53, 301), (1, 53, 82, 301), (1, 82, 103, 301), (1, 103, 125, 301), (1, 125, 185, 301), (1, 185), (1, 301)]

for region in regions:
    x = pd.DataFrame()
    for i in range(0, len(region), 2):
        start_col = region[i]
        end_col = region[i + 1]
        x = pd.concat([x, dataset.iloc[:, start_col:end_col]], axis=1)

    from sklearn.model_selection import train_test_split
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True, random_state=99)

    autoscaled_x_train = (x_train - x_train.mean()) / x_train.std()
    autoscaled_x_test = (x_test - x_train.mean()) / x_train.std()
    autoscaled_y_train = (y_train - y_train.mean()) / y_train.std()

    max_number_of_components = 20
    fold_number = 10
    components = []
    r2_in_cv_all = []
    for component in range(1, max_number_of_components + 1):
        model = PLSRegression(n_components=component)
        estimated_y_in_cv = pd.DataFrame(cross_val_predict(model, autoscaled_x_train, autoscaled_y_train, cv=fold_number))
        estimated_y_in_cv = estimated_y_in_cv * y_train.std() + y_train.mean()
        r2_in_cv = metrics.r2_score(y_train, estimated_y_in_cv)
        r2_in_cv_all.append(r2_in_cv)
        components.append(component)

    optimal_component_number = components[r2_in_cv_all.index(max(r2_in_cv_all))]
    LV.append(optimal_component_number)
    model = PLSRegression(n_components=optimal_component_number)
    model.fit(autoscaled_x_train, autoscaled_y_train)

    estimated_y_train = pd.DataFrame(model.predict(autoscaled_x_train))
    estimated_y_train = estimated_y_train * y_train.std() + y_train.mean()

    estimated_y_test = pd.DataFrame(model.predict(autoscaled_x_test))
    estimated_y_test = estimated_y_test * y_train.std() + y_train.mean()

    r2_train = metrics.r2_score(y_train, estimated_y_train)
    r2value_train.append(r2_train)
    mae_train = metrics.mean_absolute_error(y_train, estimated_y_train)
    MAE_train.append(mae_train)
    rmsec = metrics.mean_squared_error(y_train, estimated_y_train, squared=False)
    RMSEC.append(rmsec)
    rpdc = y_train.std() / rmsec
    RPDC.append(rpdc)

    r2_test = metrics.r2_score(y_test, estimated_y_test)
    r2value_test.append(r2_test)
    mae_test = metrics.mean_absolute_error(y_test, estimated_y_test)
    MAE_test.append(mae_test)
    rmsep = metrics.mean_squared_error(y_test, estimated_y_test, squared=False)
    RMSEP.append(rmsep)
    rpdp = y_test.std() / rmsep
    RPDP.append(rpdp)

r2value_train = pd.DataFrame(r2value_train)
MAE_train = pd.DataFrame(MAE_train)
RMSEC = pd.DataFrame(RMSEC)
RPDC = pd.DataFrame(RPDC)
r2value_test = pd.DataFrame(r2value_test)
MAE_test = pd.DataFrame(MAE_test)
RMSEP = pd.DataFrame(RMSEP)
RPDP = pd.DataFrame(RPDP)
LV = pd.DataFrame(LV)

index = []

# 创建索引以标识每个区段
for region in regions:
    indexx = ""
    for i in range(0, len(region), 2):
        start_wavelength = dataset.columns[region[i]]
        end_wavelength = dataset.columns[region[i + 1] - 1]
        indexx += start_wavelength + '~' + end_wavelength + ", "
    index.append(indexx[:-2]) 

data = pd.concat([r2value_train, MAE_train, RMSEC, RPDC, r2value_test, MAE_test, RMSEP, RPDP, LV], axis=1)
data.columns = ['R2_train', 'MAE_train', 'RMSEC', 'RPDC', 'R2_test', 'MAE_test', 'RMSEP', 'RPDP', 'LV']
data.index = index

data.to_csv('/content/drive/MyDrive/京大/colab/文件檔/HSI/酸/減去PLS/NMT_full_MSC.csv')
data



#<<Standardized Regression Coefficients (SRC)>>


import pandas as pd
import os
import glob
import numpy as np
import matplotlib.pyplot as plt

files = glob.glob("/content/drive/MyDrive/京大/colab/文件檔/HSI/糖酸比/HY/rHY_MSC_SRC.csv")
for file in files:
    pd.set_option('display.max_rows', 10)

    example1 = pd.read_csv('/content/drive/MyDrive/京大/colab/文件檔/HSI/糖酸比/HY/rHY_MSC_SRC.csv')
    example1.sort_values(by='standard_regression_coefficients')
    example1.iloc[:,0]

    z = pd.read_csv('/content/drive/MyDrive/京大/colab/文件檔/HSI/糖酸比/HY/rHY_MSC_SRC.csv', index_col=0)

    z.plot(xlabel='wavelength')
    plt.xlabel("wavelength(nm)", fontsize=12)
    plt.ylabel("value", fontsize=12)
    plt.xticks(np.arange(0, 300, 20))

    plt.title("Hei Ye", fontsize=14)
    plt.xlabel("wavelength(nm)", fontsize=12)
    plt.ylabel("value", fontsize=12)

    z.plot.bar()
    plt.xticks(np.arange(0, 300, 20))

plt.show()
